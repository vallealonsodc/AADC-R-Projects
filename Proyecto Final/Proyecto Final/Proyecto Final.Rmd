---
title: "Análisis del Reporte Mundial de Felicidad 2024 mediante técnicas de aprendizaje automático"
author:
  - "María del Valle Alonso de Caso Ortiz"
  - "Análisis Avanzado de Datos Clínicos"
output: html_notebook
---


# Índice

1. Introducción al proyecto

2. Datos

   2.1. Contenido
   
   2.2. Preprocesado
   
3. Análisis Exploratorio

4. Aprendizaje No Supervisado

5. Aprendizaje Supervisado - Modelos predictivos

6. Conclusiones

7. Bibliografía

# Resumen

El Reporte Mundial de Felicidad 2024 proporciona una visión integral del bienestar global, evaluando una variedad de indicadores que influyen en la felicidad de los países. En este proyecto, hemos llevado a cabo un análisis exhaustivo utilizando diversas técnicas de ciencia de datos para explorar, predecir y agrupar estos datos.

Comenzamos con un análisis exploratorio que nos permitió entender las características y tendencias principales del dataset. Posteriormente, empleamos técnicas de aprendizaje no supervisado, como el clustering, para descubrir patrones ocultos y agrupar los países en categorías basadas en sus indicadores de felicidad. Finalmente, aplicamos modelos predictivos para identificar los factores más determinantes en la felicidad de los países y estimar sus niveles de bienestar futuro.

Este enfoque multidimensional nos proporciona una comprensión profunda de los factores que contribuyen a la felicidad global y ofrece valiosas recomendaciones para mejorar el bienestar en diferentes regiones del mundo.


# 1. Introducción al proyecto

La idea del proyecto ha surgido de la búsqueda en Kaggle de proyectos de análisis de datos. En esta búsqueda, encontramos un proyecto muy completo sobre el Análisis del Reporte Mundial de Felicidad de 2017 [1]. El proyecto me generó gran curiosidad por cómo estaba planteado y por ser un tópico de divulgación bastante interesante por lo que decidí realizar yo también un Análisis pero sobre el Reporte Mundial de Felicidad 2024.

Por tanto, los datos utilizados se han extraído directamente de la página oficial del Reporte Mundial de Felicidad [2]. Estos datos se encontraron en formato xls en un excel. Una de las tareas principales del análisis ha sido limpiar los datos descargados. Primero limpiando el ''raw'' excel para que sea legible por la función R correspondiente y posteriormente realizando modificaciones sobre las variables para igualar su estructura al dataset del proyecto Kaggle.

No obstante, este proyecto no realiza algunos de los procedimientos que se realizan en el proyecto de 2017 y, por el contrario, añade procedimientos de Aprendizaje No Supervisado, para que el proyecto sea más completo con la asignatura de Análisis Avanzado de Datos Clínicos.

La ventaja de trabajar en paralelo con el proyecto del Reporte Mundial de Felicidad de 2017 es poder realizar además un estudio comparativo de las tendecias que han cambiado durante estos 7 años (2017-2024). Los resultados del estudio comparativo se presentan en el capítulo de conclusiones.

A continuación, las librerias que se han utilizado en el proyecto.

```{r}
install.packages("readxl")
install.packages("corrplot")
```
```{r}
install.packages("randomForest")
install.packages("neuralnet")
install.packages('caTools')
```
```{r}
install.packages("factoextra")
install.packages("cluster")
```

```{r}
library(plyr)
library(dplyr)
library(tidyverse)
library(lubridate)
library(caTools)
library(ggplot2)
library(ggthemes)
library(reshape2)
library(data.table)
library(tidyr)
library(corrgram)       
library(corrplot)
library(formattable)
library(cowplot)
library(ggpubr)
library(plot3D)
library(readxl)
library(e1071)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(neuralnet)
library(caTools)
library(factoextra)
library(cluster)
```

# 2. Datos

## 2.1 Contenido

Datos extraídos de la web oficial https://worldhappiness.report/ed/2024/#appendices-and-data se descargan en xls

```{r}
DATOS <- read_excel("data/world_happines_report_2024.xls")
```

Vistazo inicial del dataset

```{r}
head(DATOS)
```
```{r}
dim(DATOS)
```
```{r}
str(DATOS)
```

## 2.2 Preprocesado

En primer lugar, vamos a eliminar las variables que no aportan información importante que son upperwhisker y lowerwhisker que son intervalos de confianza de la puntuacion de felicidad
```{r}
# Variables innecesarias (Whisker.high and Whisker.low)
DATOS <- DATOS[, -c(4,5)]
```

Luego vamos a cambiar el nombre de las columnas a nombres más intuitivos y similares al dataset de kaggle

```{r}
colnames(DATOS) <- c("Country", "Happiness.Score", "Economy", "Family",
                     "Life.Expectancy", "Freedom","Generosity", "Trust", "Dystopia.Residual")
```

Añadimos una columna con el ranking del pais, que será de gran utilidad

```{r}
# Añadir una nueva columna al dataset
DATOS$`Happiness.Rank` <- 1:143
# Movemos la columna de posición
DATOS <- DATOS %>% select(Country, Happiness.Rank, everything())

```

```{r}
head(DATOS)
```

```{r}
str(DATOS)
```
Por tanto, las variables que tenemos son:

- *Country*: Nombre de los países
- *Happiness.Rank*: Posición del país basada en el Puntaje de Felicidad
- *Happiness.Score*: Medida de felicidad en una escala del 0 al 10
- *Economy*: El valor de todos los bienes y servicios finales producidos dentro de una nación en un año determinado.
- *Family*: Importancia de tener una familia
- *Life.Expectancy*: Importancia de la salud y cantidad de tiempo que las personas esperan vivir
- *Freedom*: Importancia de la libertad en cada país
- *Generosity*: La cualidad de ser amable y generoso
- *Trust*: Percepción de corrupción en un gobierno
- *Dystopia.Residual*: Actúa como una referencia

Vamos a crear una variable nueva: continentes

```{r}
DATOS$Continent <- NA

DATOS$Continent[which(DATOS$Country %in% c("Israel", "United Arab Emirates", "Singapore", "Thailand", "Taiwan Province of China", "Qatar", "Saudi Arabia", "Kuwait", "Bahrain", "Malaysia", "Uzbekistan", "Japan", "South Korea", "Turkmenistan", "Kazakhstan", "Turkey", "Hong Kong S.A.R., China", "Philippines","Jordan", "China", "Pakistan", "Indonesia", "Azerbaijan", "Lebanon", "Vietnam", "Tajikistan", "Bhutan", "Kyrgyzstan", "Nepal", "Mongolia", "Palestinian Territories", "Iran", "Bangladesh", "Myanmar", "Iraq", "Sri Lanka", "Armenia", "India", "Georgia", "Cambodia", "Afghanistan", "Yemen", "Syria"))] <- "Asia"

DATOS$Continent[which(DATOS$Country %in% c("Norway", "Denmark", "Iceland", "Switzerland", "Finland","Netherlands", "Sweden", "Austria", "Ireland", "Germany", "Belgium", "Luxembourg", "United Kingdom", "Czech Republic","Malta", "France", "Spain", "Slovakia", "Poland", "Italy", "Russia", "Lithuania", "Latvia", "Moldova", "Romania","Slovenia", "North Cyprus", "Cyprus", "Estonia", "Belarus", "Serbia", "Hungary", "Croatia", "Kosovo", "Montenegro", "Greece", "Portugal", "Bosnia and Herzegovina", "Macedonia","Bulgaria", "Albania", "Ukraine"))] <- "Europe"

DATOS$Continent[which(DATOS$Country %in% c("Canada", "Costa Rica", "United States", "Mexico", "Panama","Trinidad and Tobago", "El Salvador", "Belize", "Guatemala", "Jamaica", "Nicaragua", "Dominican Republic", "Honduras", "Haiti"))] <- "North America"

DATOS$Continent[which(DATOS$Country %in% c("Chile", "Brazil", "Argentina", "Uruguay", "Colombia", "Ecuador", "Bolivia", "Peru","Paraguay", "Venezuela"))] <- "South America"

DATOS$Continent[which(DATOS$Country %in% c("New Zealand", "Australia"))] <- "Australia"

DATOS$Continent[which(is.na(DATOS$Continent))] <- "Africa"
```

```{r}
#Mueve la columna a la segunda posición
DATOS <- DATOS %>% select(Country,Continent, everything())

#Crea un enumerado
DATOS$Continent <- as.factor(DATOS$Continent)
```

Finalmente el dataset queda:
```{r}
head(DATOS)
```
```{r}
str(DATOS)
```

# 3. Análisis Exploratorio

En esta sección, jugaremos con diferentes variables para descubrir cómo se correlacionan entre sí.

## Correlación entre variables numéricas

```{r}
# Seleccionar las columnas numéricas
Num.cols <- sapply(DATOS, is.numeric)
Cor.data <- cor(DATOS[, Num.cols], use = "complete.obs")

# Generar el gráfico de correlación
corrplot(Cor.data, method = 'color')
```

Debe haber una correlación inversa entre el "Ranking de Felicidad" y todas las demás variables numéricas. En otras palabras, cuanto menor es el ranking de felicidad, mayor es la puntuación de felicidad y mayores son los otros siete factores que contribuyen a la felicidad. Así que eliminemos el ranking de felicidad y veamos la correlación de nuevo.

```{r}
# Create a correlation plot
newdatacor = cor(DATOS[c(4:11)],use = "complete.obs")
corrplot(newdatacor, method = "color")
```

Otra forma de ver el mismo gráfico:

```{r}
# Create a correlation plot
corrplot(newdatacor, method = "number")
```

De acuerdo con el gráfico de correlación anterior, la economía, la familia y la esperanza de vida juegan el papel más significativo en contribuir a la felicidad. La confianza y la generosidad tienen el menor impacto en la puntuación de felicidad.

## Correlación de la felicidad con otras variables según el continente

### Matriz de correlación

```{r}
# Gráfico 1: Matriz de Felicidad para África
corrgram(DATOS %>% select(-3) %>% filter(Continent == "Africa"), order = TRUE,
         upper.panel = panel.cor, main = "Matriz de Felicidad para África")
```
**Correlación entre Happiness.Score y el resto de variables en África**
- Economy > Family > Life.Expectancy > Dystopia.Residual > Freedom
- No hay apenas correlación entre la puntuación de felicidad y la generosidad.

```{r}
# Gráfico 2: Matriz de Felicidad para Asia
corrgram(DATOS %>% select(-3) %>% filter(Continent == "Asia"), order = TRUE,
         upper.panel = panel.cor, main = "Matriz de Felicidad para Asia")
```
**Correlación entre Happiness.Score y el resto de variables en Asia**
- Economy > Family > Dystopia.Residual > Freedom > Life.Expectancy > Trust > Generosity 
- No hay apenas correlación entre la puntuación de felicidad y la generosidad.


```{r}
# Gráfico 3: Matriz de Felicidad para Europa
corrgram(DATOS %>% select(-3) %>% filter(Continent == "Europe"), order = TRUE,
         upper.panel = panel.cor, main = "Matriz de Felicidad para Europa")
```
**Correlación entre Happiness.Score y el resto de variables en Europa**
- Economy >  Trust > Life.Expectancy > Freedom > Family > Dystopia.Residual > Generosity

```{r}
# Gráfico 4: Matriz de Felicidad para América del Norte
corrgram(DATOS %>% select(-3) %>% filter(Continent == "North America"), order = TRUE,
         upper.panel = panel.cor, main = "Matriz de Felicidad para América del Norte")
```
**Correlación entre Happiness.Score y el resto de variables en América del Norte**
- Economy >  Life.Expectancy > Family > Trust > Generosity 
- La mejor puntuación de correlación para la generosidad se alcanza en América del Norte
- No hay apenas correlación entre la puntuación de felicidad y la libertad o la referencia a la distopia.

```{r}
# Gráfico 5: Matriz de Felicidad para América del Sur
corrgram(DATOS %>% select(-3) %>% filter(Continent == "South America"), order = TRUE,
         upper.panel = panel.cor, main = "Matriz de Felicidad para América del Sur")
```
**Correlación entre Happiness.Score y el resto de variables en América del Sur**
- Economy >  Trust > Family > Freedom > Life.Expectancy
- La correlación entre la puntuación de felicidad y la referencia a la distopia es inversa
- No hay apenas correlación entre la puntuación de felicidad y la generosidad

## Scatter plot con regresión

Es importante que no tendremos en cuenta a Australia porque solo hay dos países en Australia y crear un gráfico de dispersión con la línea de regresión para este continente no nos dará ninguna idea.

```{r}
ggplot(subset(DATOS, DATOS$Continent != "Australia"), aes(x = Life.Expectancy, y = Happiness.Score)) + 
  geom_point(aes(color=Continent), size = 3, alpha = 0.8) +  
  geom_smooth(aes(color = Continent, fill = Continent), 
              method = "lm", fullrange = TRUE) +
  facet_wrap(~Continent) +
  theme_bw() + labs(title = "Scatter plot para Esperanza de vida")
```
**Correlación entre Happiness.Score y Life.Expectancy**

La correlación entre la esperanza de vida y el puntaje de felicidad en Europa, América del Norte y Asia es más significativa que en los demás continentes. 

```{r}
ggplot(subset(DATOS, DATOS$Continent != "Australia"), aes(x = Economy, y = Happiness.Score)) + 
  geom_point(aes(color=Continent), size = 3, alpha = 0.8) +  
  geom_smooth(aes(color = Continent, fill = Continent), 
              method = "lm", fullrange = TRUE) +
  facet_wrap(~Continent) +
  theme_bw() + labs(title = "Scatter plot para Economía")
```
**Correlación entre Happiness.Score y Economy**

La correlación entre la economía y el puntaje de felicidad se comporta de forma similar en todos los continentes a excepción de África, donde la puntuación es menos signficativa. 

```{r}
ggplot(subset(DATOS, DATOS$Continent != "Australia"), aes(x = Freedom, y = Happiness.Score)) + 
  geom_point(aes(color=Continent), size = 3, alpha = 0.8) +  
  geom_smooth(aes(color = Continent, fill = Continent), 
              method = "lm", fullrange = TRUE) +
  facet_wrap(~Continent) +
  theme_bw() + labs(title = "Scatter plot para Libertad")
```
**Correlación entre Happiness.Score y Freedom**

La correlación entre la libertad y el puntaje de felicidad es más significativa en Europa y Norte América, seguida de Sudamérica. En Asia también aunque está más disperso. En África los valores en general son más bajos.

```{r}
ggplot(subset(DATOS, DATOS$Continent != "Australia"), aes(x = Trust, y = Happiness.Score)) + 
  geom_point(aes(color=Continent), size = 3, alpha = 0.8) +  
  geom_smooth(aes(color = Continent, fill = Continent), 
              method = "lm", fullrange = TRUE) +
  facet_wrap(~Continent) +
  theme_bw() + labs(title = "Scatter plot para Confianza")
```
**Correlación entre Happiness.Score y Trust**

La correlación entre la puntuación de felicidad y la confianza es bastante más baja en todos los continentes, con especial desinterés en África.

```{r}
ggplot(subset(DATOS, DATOS$Continent != "Australia"), aes(x = Generosity, y = Happiness.Score)) + 
  geom_point(aes(color=Continent), size = 3, alpha = 0.8) +  
  geom_smooth(aes(color = Continent, fill = Continent), 
              method = "lm", fullrange = TRUE) +
  facet_wrap(~Continent) +
  theme_bw() + labs(title = "Scatter plot para Generosidad")
```

**Correlación entre Happiness.Score y Generosity**

La correlación entre la la puntuación de felicidad y la generosidad destaca por su desinterés en África y en Sudamérica, donde la correlación es negativa.

```{r}
ggplot(subset(DATOS, DATOS$Continent != "Australia"), aes(x = Family, y = Happiness.Score)) + 
  geom_point(aes(color=Continent), size = 3, alpha = 0.8) +  
  geom_smooth(aes(color = Continent, fill = Continent), 
              method = "lm", fullrange = TRUE) +
  facet_wrap(~Continent) +
  theme_bw() + labs(title = "Scatter plot para Familia")
```
**Correlación entre Happiness.Score y Family**

La correlación entre la puntuación de Felicidad y la Familia es positiva en todos los continentes, con especial interés en Europa, Norte América y Sudamérica

```{r}
ggplot(subset(DATOS, DATOS$Continent != "Australia"), aes(x = Dystopia.Residual, y = Happiness.Score)) + 
  geom_point(aes(color=Continent), size = 3, alpha = 0.8) +  
  geom_smooth(aes(color = Continent, fill = Continent), 
              method = "lm", fullrange = TRUE) +
  facet_wrap(~Continent) +
  theme_bw() + labs(title = "Scatter plot para la referencia de Distopía")
```

**Correlación entre Happiness.Score y Dystopia.Residual**

La correlación entre la la puntuación de felicidad y la referencia de la distopía destaca por su relación inversa en Sudamérica y el especial interés en Asia y Europa.

## Distribución del puntaje de felicidad según el continente

### Box plot

```{r}
gg1 <- ggplot(DATOS,
              aes(x=Continent,
                  y=Happiness.Score,
                  color=Continent))+
  geom_point() + theme_bw() +
  theme(axis.title = element_text(size = (8)))

gg2 <- ggplot(DATOS , aes(x = Continent, y = Happiness.Score)) +
  geom_boxplot(aes(fill=Continent)) + theme_bw() +
  theme(axis.title = element_text( size = (8)))

gg3 <- ggplot(DATOS,aes(x=Continent,y=Happiness.Score))+
  geom_violin(aes(fill=Continent),alpha=0.7)+ theme_bw() +
  theme(axis.title = element_text( size = (8)))

stable <- desc_statby(DATOS, measure.var = "Happiness.Score",
                      grps = "Continent")
stable <- stable[, c("Continent","mean","median")]
names(stable) <- c("Continent", "Mean of happiness score","Median of happiness score")
# Summary table plot
stable.p <- ggtexttable(stable,rows = NULL, 
                         theme = ttheme("classic"))


ggarrange(gg1, gg2, ncol = 1, nrow = 2)
ggarrange(gg3, stable.p, ncol = 1, nrow = 2)
```
Australia tiene la mediana de la puntuación de felicidad más alta. Europa y América del Norte están en segundo lugar. En tercer lugar, Sudamérica y después Asia. Finalmente África tiene la puntuación de felicidad más baja. Podemos observar el rango de puntajes de felicidad para diferentes continentes, así como la concentración de puntajes de felicidad.

# 4. Aprendizaje No Supervisado

A pesar de que el ejercicio de Kaggle no lo incluye, en nuestro ejercicio utilizaremos técnicas de aprendizaje no supervisado para analizar y comprender mejor el Reporte Mundial de Felicidad. El objetivo principal de aplicar aprendizaje no supervisado en este contexto es descubrir patrones subyacentes y agrupaciones naturales entre los países basados en estos indicadores.

En primer lugar preparamos los datos.

```{r}
data_scaled <- scale(DATOS[, 4:11])
data_scaled <- na.omit(data_scaled)
```

### Clustering Jerárquico

Vamos a aplicar clustering jerárquico para a través del dendograma ver cuál puede ser el número recomendado de clusters.

```{r}
# Calcular la matriz de distancias
dist_matrix <- dist(data_scaled)

# Crear el dendrograma
hc_result <- hclust(dist_matrix, method = "ward.D2")

# Dendrograma
fviz_dend(hc_result, rect = TRUE) #Esta función funciona mejor para visualizar que plot(hc_result)
```
Parece que el numero de clusters óptimo podria ser entre 2 y 3.

```{r}
# Cortar el dendrograma en 2 clusters 
cluster_assignments <- cutree(hc_result, k = 2)

# Visualizar los clusters
fviz_cluster(list(data = data_scaled, cluster = cluster_assignments))
```
```{r}
# Cortar el dendrograma en 3 clusters 
cluster_assignments <- cutree(hc_result, k = 3)

# Visualizar los clusters
fviz_cluster(list(data = data_scaled, cluster = cluster_assignments))
```
Los clusters se pisan entre sí luego la tarea no tiene gran precisión. Probaremos otro algoritmo.

## K-Means

```{r}
# K=2
kmeans_result_2 <- kmeans(data_scaled, centers = 2, nstart = 25)

# Visualizar los clusters
fviz_cluster(kmeans_result, data = data_scaled)
```

```{r}
# K=3
kmeans_result_3 <- kmeans(data_scaled, centers = 3, nstart = 25)

# Visualizar los clusters
fviz_cluster(kmeans_result, data = data_scaled)
```
Con la técnica del K-Means la separación entre clústers es mucho mejor. Aunque se pisan en algunas regiones, estas regiones son mucho menores que en el caso del modelo jerarquico.

## Comparación entre modelos

Los valores (i,j) representan el número de puntos que se reparten en los clusteres i,j de cada algoritmo.

```{r}
table(kmeans_result_2$cluster, #filas=algoritmo kmeans
      cutree(hc_result, k=2)) #columnas= algoritmo jerarquico
```
Por ejemplo, si fijo las filas, observo que que:
- Del cluster 1 del Kmeans, se reparten 8 puntos en el cluster 1 y 48 puntos en el cluster 2 del Jerárquico.
- Del cluster 2 del Kmeans, se reparten 80 puntos en el cluster 1, y 4 en el cluster 2 del Jerárquico.

```{r}
table(kmeans_result_3$cluster, #filas=algoritmo kmeans
      cutree(hc_result, k=3)) #columnas= algoritmo jerarquico
```
La misma interpretación se puede realizar para esta tabla.

# 5. Aprendizaje Supervisado - Modelos predictivos

En esta sección, implementaremos varios algoritmos de aprendizaje automático para predecir el puntaje de felicidad. Primero, debemos dividir nuestro conjunto de datos en un conjunto de entrenamiento y otro de prueba. Nuestra variable dependiente es el puntaje de felicidad, y las variables independientes son la familia, la economía, la esperanza de vida, la confianza, la libertad, la generosidad y el residuo de distopía.

```{r}
# Fija la semilla para que el experimento sea reproducible
set.seed(123)

# Divide en conjunto de entrenamiento y conjunto de prueba
dataset <- DATOS[4:11]
split = sample.split(dataset$Happiness.Score, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Eliminar los valores faltantes para evitar conflictos con los modelos
dataset <-  na.omit(dataset)
training_set <-  na.omit(training_set)
test_set <- na.omit(test_set)

```

## Regresión Linear Múltiple

```{r}
# Fitting Multiple Linear Regression to the Training set
regressor_lm = lm(formula = Happiness.Score ~ .,
               data = training_set)

summary(regressor_lm)
```
- Variables significativas: Las variables Economy y Life.Expectancy tienen coeficientes significativos y positivos, lo que sugiere que un aumento en la economía y la esperanza de vida está asociado con un aumento en el puntaje de felicidad.

- Variable no significativa: La variable Freedom no es estadísticamente significativa, lo que sugiere que su inclusión en el modelo puede no ser útil para predecir el puntaje de felicidad.

- Alto R-cuadrado: El modelo explica aproximadamente el 99.97% de la variabilidad en el puntaje de felicidad, lo que sugiere que las variables incluidas explican bien la variación en el puntaje de felicidad.

```{r}
####### Predicción del Test
y_pred_lm = predict(regressor_lm, newdata = test_set)

Pred_Actual_lm <- as.data.frame(cbind(Prediction = y_pred_lm, Actual = test_set$Happiness.Score))

gg.lm <- ggplot(Pred_Actual_lm, aes(Actual, Prediction )) +
  geom_point() + theme_bw() + geom_abline() +
  labs(title = "Multiple Linear Regression", x = "Actual happiness score",
       y = "Predicted happiness score") +
  theme(plot.title = element_text( face = "bold", size = (15)), 
        axis.title = element_text( size = (10)))
gg.lm

```
Como era de esperar, los valores reales con los predichos muestran una regresión linear prácticamente perfecta, mostrando una gran precisión del modelo.


## Support Vector Regression - SVR

```{r}
# Fitting SVR to the dataset
regressor_svr = svm(formula = Happiness.Score ~ .,
                data = dataset,
                type = 'eps-regression',
                kernel = 'radial')

summary(regressor_svr)
```
En este caso el resumen no muestra información sobre las variables sino simplemente sobre cómo se ajustan los parámetros internos del modelo  

```{r}
# Predicting a new result
y_pred_svr = predict(regressor_svr,  newdata = test_set)

Pred_Actual_svr <- as.data.frame(cbind(Prediction = y_pred_svr, Actual = test_set$Happiness.Score))


Pred_Actual_lm.versus.svr <- cbind(Prediction.lm = y_pred_lm, Prediction.svr = y_pred_svr, Actual = test_set$Happiness.Score)


gg.svr <- ggplot(Pred_Actual_svr, aes(Actual, Prediction )) +
  geom_point() + theme_bw() + geom_abline() +
  labs(title = "SVR", x = "Actual happiness score",
       y = "Predicted happiness score") +
  theme(plot.title = element_text( face = "bold", size = (15)), 
        axis.title = element_text( size = (10)))
gg.svr
```
El modelo SVR  proporciona una predicción de precisión buena aunque peor que la de la Regresión Linear Múltiple

## Árbol de decisión

```{r}
# Fitting Decision Tree Regression to the dataset
regressor_dt = rpart(formula = Happiness.Score ~ .,
                  data = dataset,
                  control = rpart.control(minsplit = 10))

summary(regressor_dt)
```
En este caso, el resumen devuelve una descripción textual del árbol de decisión que construye el modelo. No obstante, es más intuitivo visualizar directamente el árbol, como realizaremos a continuación.

En comparación con el resumen obtenido para la Regresión Linear Múltiple, las variables más significativas en este caso son Economy, Family y Life Expectancy y las menos significativas Generosity y Trust

```{r}
# Plotting the tree
prp(regressor_dt)
```
El árbol de decisión que devuelve es algo raro porque todas las particiones se hacen sobre el mismo atributo ''Economy''.

```{r}
# Predicting a new result with Decision Tree Regression
y_pred_dt = predict(regressor_dt, newdata = test_set)

Pred_Actual_dt <- as.data.frame(cbind(Prediction = y_pred_dt, Actual = test_set$Happiness.Score))


gg.dt <- ggplot(Pred_Actual_dt, aes(Actual, Prediction )) +
  geom_point() + theme_bw() + geom_abline() +
  labs(title = "Decision Tree Regression", x = "Actual happiness score",
       y = "Predicted happiness score") +
  theme(plot.title = element_text(family = "Helvetica", face = "bold", size = (15)), 
        axis.title = element_text(family = "Helvetica", size = (10)))
gg.dt
```

El árbol de decisión no proporciona un resultado del todo malo pero comparado con los resultados anteriores podríamos decir que tampoco es la mejor opción.

## Random Forest Regressión

```{r}
# Fitting Random Forest Regression to the dataset
regressor_rf = randomForest(x = dataset[-1],
                         y = dataset$Happiness.Score,
                         ntree = 500)

summary(dataset)
```
Del resumen obtenemos nuevamente que la economía, la familia y la esperanza de vida tienen valores que van desde mínimos relativamente bajos hasta máximos bastante altos, lo que sugiere que tienen un impacto significativo. Por otro lado la generosidad y la confianza  tienen rangos más estrechos y valores medios más bajos en comparación con las variables anteriores, es decir, tienen menor impacto.

```{r}
y_pred_rf = predict(regressor_rf, newdata = test_set)

Pred_Actual_rf <- as.data.frame(cbind(Prediction = y_pred_rf, Actual = test_set$Happiness.Score))


gg.rf <- ggplot(Pred_Actual_rf, aes(Actual, Prediction )) +
  geom_point() + theme_bw() + geom_abline() +
  labs(title = "Random Forest Regression", x = "Actual happiness score",
       y = "Predicted happiness score") +
  theme(plot.title = element_text(family = "Helvetica", face = "bold", size = (15)), 
        axis.title = element_text(family = "Helvetica", size = (10)))
gg.rf
```
El Random Forest Regression provee una predicción bastante mejor ajustada que la anterior, con una precisión bastante buena.

## Red Neuronal

```{r}
# Fitting Neural Net to the training set
nn <- neuralnet(Happiness.Score ~ Economy + Family + Life.Expectancy + Freedom + Generosity + Trust + Dystopia.Residual,
                data=training_set,hidden=10,linear.output=TRUE)
summary(nn)
```
En este caso, como sucedía con SVR, el resumen proporciona datos internos del modelo. Mejor vamos a visualizar la red neuronal.
```{r}
plot(nn)
```
```{r}
predicted.nn.values <- compute(nn,test_set[,2:8])

Pred_Actual_nn <- as.data.frame(cbind(Prediction = predicted.nn.values$net.result, Actual = test_set$Happiness.Score))

gg.nn <- ggplot(Pred_Actual_nn, aes(Actual, V1 )) +
  geom_point() + theme_bw() + geom_abline() +
  labs(title = "Neural Net", x = "Actual happiness score",
       y = "Predicted happiness score") +
  theme(plot.title = element_text(family = "Helvetica", face = "bold", size = (15)), 
      axis.title = element_text(family = "Helvetica", size = (10)))
gg.nn
```

El modelo de Red Neuronal se ajusta prácticamente a la perfección a los datos. Podríamos decir que tiene una precisión óptima junto a la Regresión Linear Múltiple. Vamos a comparar las métricas de regresión:

```{r}
MSE.lm <- sum((test_set$Happiness.Score - y_pred_lm)^2)/nrow(test_set)
MSE.nn <- sum((test_set$Happiness.Score - predicted.nn.values$net.result)^2)/nrow(test_set)

print(paste("Mean Squared Error (Multiple Linear Regression):", MSE.lm))
print(paste("Mean Squared Error (Neural Net):", MSE.nn))
```
Dado que el MSE del modelo de regresión lineal múltiple es menor que el del modelo de red neuronal, se podría concluir que el modelo de regresión lineal múltiple es mejor en términos de ajuste a los datos de prueba.

## Comparación entre modelos

```{r}
ggarrange(gg.lm, gg.svr, gg.dt, gg.rf, gg.nn, ncol = 2, nrow = 3)
```

La regresión lineal múltiple y la red neuronal hicieron el mejor trabajo y predijeron aproximadamente lo mismo. SVR y Random Forest ocuparon el segundo lugar en cuanto a precisión en la predicción. Y finalmente, el árbol de decisiones fue el peor algoritmo para predecir los puntajes de felicidad.


# 6. Conclusiones 

Finalmente, de todo el análisis y la comparación con el Reporte Mundial de Felicidad de 2017 [1], destacamos las siguientes conclusiones:

- **La importancia del análisis exploratorio.** Más allá de aplicar de algoritmos de ML también se puede extraer información MUY significativa mediante la exploración visual del dataset. En este caso, el análisis exploratorio ha sido fundamental para entender la improtancia de las diferentes variables en la puntuación del Felicidad obtenida.

- **Diferentes tendencias a lo largo del tiempo.** Como era de esperar, pasados 7 años entre el proyecto de Kaggle y este proyecto, en numerosas ocasiones sobre todo durante el análisis exploratorio, las tendencias habían cambiado y variables que antes eran muy significativas ahora no lo eran y viceversa. Destacaría la importancia actual de la economía en prácticamente todos los continentes.

- **Beneficios del Aprendizaje No Supervisado.** A pesar de que el proyecto de Kaggle no realizaba análisis no supervisado, creo que ha sido muy positivo para el proyecto haber aplicado algunas de estas técnicas, también para poder comparar entre agrupación y predicción y extraer resultados de formas distintas.


# 7. Bibliografía

[1] Proyecto del Reporte Mundial de Felicidad 2017. https://www.kaggle.com/code/javadzabihi/happiness-2017-visualization-prediction/input?select=2017.csv. 

[2] Página web oficial del Reporte Mundial de Felicidad 2024. https://worldhappiness.report/ed/2024/#appendices-and-data





